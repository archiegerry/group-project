{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook can be used to create rolling averages of the different sentiment sources"
      ],
      "metadata": {
        "id": "2-uzjc0lpTtG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VntFYiV9a-N"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V42dTBO2_osl"
      },
      "outputs": [],
      "source": [
        "#Load the data from the parquet file\n",
        "#1. Running on google colab - upload the roberta.parquet file\n",
        "#df = pd.read_parquet('/content/roberta.parquet')\n",
        "\n",
        "#2. Running on vscode\n",
        "df = pd.read_parquet('roberta.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAwqS0_F_34l"
      },
      "outputs": [],
      "source": [
        "#Quick overview of the data\n",
        "print(\"Columns in the dataset:\", df.columns.tolist())\n",
        "print(\"First few rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"Missing values in news sentiment:\", df['news_sentiment'].isnull().sum())\n",
        "print(\"Missing values in submissions sentiment:\", df['submissions_sentiment'].isnull().sum())\n",
        "print(\"Missing values in comments sentiment:\", df['comments_sentiment'].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter the DataFrame to only include dates between 2014-01-01 and 2022-01-01\n",
        "truncated = df[(df['dt'] >= '2014-01-01') & (df['dt'] <= '2022-01-01')]"
      ],
      "metadata": {
        "id": "mu538CkeyWeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1-Ts3ajIBFs"
      },
      "outputs": [],
      "source": [
        "sentiment_df = truncated.copy()\n",
        "sentiment_df = sentiment_df.drop(columns= ['open', 'close', 'high', 'low', 'sp500_open', 'sp500_close'])\n",
        "sentiment_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75o7Zg_uFnY7"
      },
      "outputs": [],
      "source": [
        "df_clean = sentiment_df.copy()\n",
        "df_clean[['news_sentiment', 'submissions_sentiment', 'comments_sentiment']] = \\\n",
        "    df_clean[['news_sentiment', 'submissions_sentiment', 'comments_sentiment']].fillna(0)\n",
        "\n",
        "print(\"Data after filling missing sentiment values with 0:\")\n",
        "display(df_clean.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA5FalcQGCDx"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Missing values in news sentiment:\", df_clean['news_sentiment'].isnull().sum())\n",
        "print(\"Missing values in submissions sentiment:\", df_clean['submissions_sentiment'].isnull().sum())\n",
        "print(\"Missing values in comments sentiment:\", df_clean['comments_sentiment'].isnull().sum())\n",
        "\n",
        "# Check data types and missing values\n",
        "print(\"\\nData Info:\")\n",
        "df_clean.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIg0blsQwnl9"
      },
      "outputs": [],
      "source": [
        "if 'dt' in df_clean.columns:\n",
        "    df_clean['dt'] = pd.to_datetime(df_clean['dt'])\n",
        "    df_clean = df_clean.sort_values('dt')\n",
        "    df_clean.set_index('dt', inplace=True)\n",
        "display(df_clean.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJNWYh0NyPrp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_rolling_30_day_mean(symbol_df, column_name):\n",
        "    \"\"\"\n",
        "    Computes the rolling 30‑day mean for the specified column in the symbol DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "      symbol_df (DataFrame): The DataFrame for a single symbol, with a datetime index.\n",
        "      column_name (str): The column for which to compute the rolling 30‑day mean.\n",
        "\n",
        "    Returns:\n",
        "      tuple: (updated DataFrame, rolling mean Series)\n",
        "    \"\"\"\n",
        "    # Ensure the DataFrame is sorted by the datetime index\n",
        "    symbol_df = symbol_df.sort_index()\n",
        "\n",
        "    # Compute the rolling mean over a window of 30 days.\n",
        "    rolling_col = f\"{column_name}_rolling_30d_mean\"\n",
        "    symbol_df[rolling_col] = symbol_df[column_name].rolling(window=30, min_periods=1).mean()\n",
        "\n",
        "    return symbol_df, symbol_df[rolling_col]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit source of sentiment - comments_sentiment / submission_sentiment / news_sentiment to generate rollingMean for each sentiment source"
      ],
      "metadata": {
        "id": "JDpFkIkPpuBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVddvFkh0Bag",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Get unique symbols from df_clean\n",
        "symbols = df_clean['symbol'].unique()\n",
        "\n",
        "# Dictionary to store transitions for each symbol (using 'news_sentiment'; adjust as needed)\n",
        "symbol_transitions = {}\n",
        "\n",
        "for symbol in symbols:\n",
        "    # Filter data for the current symbol and make a copy to ensure independence\n",
        "    df_symbol = df_clean[df_clean['symbol'] == symbol].copy()\n",
        "\n",
        "    # (Optional) Debug: Print the number of data points for this symbol\n",
        "    print(f\"Symbol: {symbol}, Data points: {len(df_symbol)}\")\n",
        "    display(df_symbol.head())\n",
        "\n",
        "    # Compute transitions using the symbol-specific DataFrame\n",
        "    period_df, transitions = compute_rolling_30_day_mean(df_symbol, 'comments_sentiment')\n",
        "\n",
        "    # Debug print to verify period DataFrame and transitions\n",
        "    print(f\"Symbol: {symbol} Period DataFrame:\")\n",
        "    display(period_df)\n",
        "    print(f\"Symbol: {symbol} Transitions:\")\n",
        "    display(transitions.dropna())\n",
        "\n",
        "    # Only store if there is valid transition data\n",
        "    if not transitions.empty:\n",
        "        symbol_transitions[symbol] = transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename parquet file generated to match the sentiment source"
      ],
      "metadata": {
        "id": "HZxuVqJ7qBVE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ83YS4DiPxv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def resample_transitions(transitions, freq='30D'):\n",
        "    # Assume the index of transitions is a datetime index\n",
        "    return transitions.resample(freq).mean()\n",
        "\n",
        "# Combine transitions after resampling\n",
        "all_transitions = []\n",
        "for symbol, transitions in symbol_transitions.items():\n",
        "    # Resample transitions to 30-day frequency\n",
        "    transitions_resampled = resample_transitions(transitions)\n",
        "\n",
        "    # Reset index so that the date becomes a column\n",
        "    tmp = transitions_resampled.reset_index()\n",
        "    # Rename columns (assuming the datetime column was named 'dt' or similar)\n",
        "    tmp.columns = ['date', 'comments_sentiment']\n",
        "    tmp['symbol'] = symbol\n",
        "    all_transitions.append(tmp)\n",
        "\n",
        "# Concatenate all symbol transitions into one DataFrame\n",
        "transitions_df = pd.concat(all_transitions, ignore_index=True)\n",
        "\n",
        "# Save as a Parquet file\n",
        "transitions_df.to_parquet('rollingComments.parquet', index=False)\n",
        "\n",
        "# To verify, load it back:\n",
        "loaded_transitions = pd.read_parquet('rollingComments.parquet')\n",
        "print(loaded_transitions.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the output directory in /content/\n",
        "output_dir = \"/content/rollingComments\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "lNXwUpNek11O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transitions DataFrame from the saved Parquet file\n",
        "transitions_df = pd.read_parquet('rollingComments.parquet')\n",
        "\n",
        "# Get the unique symbols from the transitions DataFrame\n",
        "symbols = transitions_df['symbol'].unique()\n",
        "\n",
        "# Loop through each symbol and plot its transitions\n",
        "for symbol in symbols:\n",
        "    # Filter transitions for the current symbol and sort by date\n",
        "    df_symbol = transitions_df[transitions_df['symbol'] == symbol].copy()\n",
        "    df_symbol.sort_values('date', inplace=True)\n",
        "\n",
        "    # Create a new figure for this symbol\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(df_symbol['date'], df_symbol['comments_sentiment'], marker='o')\n",
        "    plt.xlabel(\"Date (Start of Next Period)\")\n",
        "    plt.ylabel(\"Rolling Mean (Comments Sentiment)\")\n",
        "    plt.title(f\"Reddit Comments Sentiment Rolling Mean for {symbol}\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Define the file path for saving the figure in /content/plots\n",
        "    output_path = os.path.join(output_dir, f\"comments_rolling_{symbol}.png\")\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(output_path)\n",
        "\n",
        "    # Close the figure to free up memory\n",
        "    plt.close()\n",
        "\n",
        "print(f\"All figures have been saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "_wZjRNTgkq_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the folder\n",
        "!zip -r /content/rollingComments.zip /content/rollingComments\n"
      ],
      "metadata": {
        "id": "xF1gzrpVmWx7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}